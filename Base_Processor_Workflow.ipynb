{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demonstrates the Base workflow with the Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowcode\n",
    "import processing\n",
    "import res_flow_vis as visual\n",
    "import device_use\n",
    "import externalize as ext\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filename associated with this specific run\n",
    "filename = \"leavout_MttZ_all_CL2_24_10_512_8_lo[66, 20, 88, 48, 5]\" #\"leavout_MttZ_MWs_CL2_24_10_512_8_lo5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate a processor to handle data\n",
    "mpc = processing.Processor_cond()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load raw data\n",
    "Galaxies_raw = mpc.get_data(\"all_sims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut out 5 of 95 galaxies, 2072015 of 34878379 stars (~6%).\n"
     ]
    }
   ],
   "source": [
    "#Clean data\n",
    "Galaxies_cleaned = mpc.constraindata(Galaxies_raw, N_min=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chose 90 of 90 galaxies.\n",
      "Chose 85 of 90 galaxies.\n"
     ]
    }
   ],
   "source": [
    "#Chose a subset of the data\n",
    "#Conditions to use:\n",
    "#Given by function, will contain computation instructions of conditions from galaxy data and their names\n",
    "cond_fn = ext.cond_M_stars_2age_avZ\n",
    "#Subset to view for comaprison (all galaxies):\n",
    "use_fn_view = ext.construct_all_galaxies_leavout(\"id\", [])\n",
    "Galaxies = mpc.choose_subset(Galaxies_cleaned, use_fn = use_fn_view, cond_fn=cond_fn)\n",
    "\n",
    "#Subset to train on (e.g. leave one out):\n",
    "leavout_idices = [66, 20, 88, 48, 5]\n",
    "use_fn_train = ext.construct_all_galaxies_leavout(\"id\", leavout_idices)\n",
    "Galaxies_train = mpc.choose_subset(Galaxies_cleaned, use_fn = use_fn_train, cond_fn=cond_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose device\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters of the flow\n",
    "LAYER_TYPE = flowcode.NSF_CL2\n",
    "N_LAYERS = 24\n",
    "COND_NAMES = mpc.cond_names[\"galaxy\"]\n",
    "DIM_COND = len(COND_NAMES)\n",
    "DIM_NOTCOND = len(Galaxies_train[0][\"stars\"]) - DIM_COND\n",
    "SPLIT = 0.5\n",
    "K = 10\n",
    "B = 3\n",
    "BASE_NETWORK = flowcode.MLP\n",
    "BASE_NETWORK_N_LAYERS = 8\n",
    "BASE_NETWORK_N_HIDDEN = 512\n",
    "BASE_NETWORK_LEAKY_RELU_SLOPE = 0.2\n",
    "\n",
    "SPLIT = {\"split\":SPLIT} if LAYER_TYPE == flowcode.NSF_CL else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "model = flowcode.NSFlow(N_LAYERS, DIM_NOTCOND, DIM_COND, LAYER_TYPE, **SPLIT, K=K, B=B, network=BASE_NETWORK, network_args=(BASE_NETWORK_N_HIDDEN,BASE_NETWORK_N_LAYERS,BASE_NETWORK_LEAKY_RELU_SLOPE))\n",
    "model = model.to(device)\n",
    "#Load pre-trained model\n",
    "#model.load_state_dict(torch.load(\"saves/leavout_M_star_MWs_CL2_24_10_512_8_lo1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "N_EPOCHS = 12\n",
    "INIT_LR = 0.00009\n",
    "GAMMA = 0.998\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "#Define indices for preprocessing\n",
    "LOG_LEARN = ([\"M_stars\"],)\n",
    "\n",
    "#Define how to scale the data to learn in a different space\n",
    "transformations = (np.log10, )\n",
    "trf_names = (LOG_LEARN, )\n",
    "transformations_inv = (lambda x: 10**x, )\n",
    "\n",
    "#For demonstration purposes:\n",
    "logdets = (ext.logdet_log10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for flow\n",
    "Data_flow = mpc.Data_to_flow(mpc.diststack(Galaxies_train), transformations, trf_names, transformations_inv, transformation_logdets=logdets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training takes long, so usually we do not want it in a notebook but in a nohup background process\n",
    "#E.g. it is possible to use the cond_trainer.py script to train the model\n",
    "#this will export the model and data accordingly to the cond_trainer folder\n",
    "torch.save(Data_flow, \"cond_trainer/data_cond_trainer.pth\")\n",
    "torch.save(model, \"cond_trainer/model_cond_trainer.pth\")\n",
    "np.save(\"cond_trainer/params_cond_trainer.npy\", np.append(COND_NAMES,np.array([N_EPOCHS,INIT_LR,BATCH_SIZE,GAMMA])))\n",
    "np.save(\"cond_trainer/filename_cond_trainer.npy\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start background training\n",
    "#nohup python cond_trainer.py <name_suffix> <optional:GPU id> &\n",
    "#Will save model in saves folder with loss history and train time (last entry in loss history)\n",
    "#Will flush training information to a textfile containing the name suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...OR train directly in notebook/current process\n",
    "import time\n",
    "train_loss_saver = []\n",
    "start = time.perf_counter()\n",
    "flowcode.train_flow(model, Data_flow, COND_NAMES, N_EPOCHS, lr=INIT_LR, batch_size=BATCH_SIZE, loss_saver=train_loss_saver, gamma=GAMMA)\n",
    "end = time.perf_counter()\n",
    "torch.save(model.state_dict(), f\"saves/{filename}.pth\")\n",
    "np.save(f\"saves/loss_{filename}.npy\",np.array(train_loss_saver+[end-start]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in training results:\n",
    "model.load_state_dict(torch.load(f\"saves/{filename}.pth\", map_location=device))\n",
    "loss_results = np.load(f\"saves/loss_{filename}.npy\")\n",
    "loss_results, tot_time = loss_results[:-1], loss_results[-1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to sample: 26 minutes and 41 seconds\n"
     ]
    }
   ],
   "source": [
    "#Get a sample from the flow\n",
    "use_GPUs = [9]\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "#Set a condition for the sample\n",
    "#Here, sample back all galaxies\n",
    "condition = mpc.diststack(Galaxies)[COND_NAMES]\n",
    "\n",
    "#Get sample\n",
    "flow_sample = mpc.sample_to_Data(mpc.sample_Conditional(model, condition, split_size=int(6e5), GPUs=use_GPUs))\n",
    "\n",
    "#To revert to a galaxy interpretation we need to specify the number of stars in each galaxy\n",
    "#Again, we use the same as in the data\n",
    "N_stars_galaxies = mpc.get_array(Galaxies, \"galaxy\" ,\"N_stars\")\n",
    "#or\n",
    "N_stars_galaxies = np.array([len(galaxy[\"stars\"]) for galaxy in Galaxies])\n",
    "\n",
    "#Convert sample to galaxy interpretation\n",
    "flow_sample = mpc.galaxysplit(flow_sample, N_stars_galaxies)\n",
    "\n",
    "#However this is now list of pandas dataframes, not a list of dictionaries as the original data\n",
    "#we can convert it back to a list of dictionaries\n",
    "flow_sample = [{\"stars\":galaxy_stars} for galaxy_stars in flow_sample]\n",
    "#In our special case, we can also reinsert the galaxy information that we know from the original data\n",
    "#This is of course not possible in general\n",
    "for galaxy_flow, galaxy in zip(flow_sample, Galaxies):\n",
    "    galaxy_flow[\"galaxy\"] = galaxy[\"galaxy\"]\n",
    "\n",
    "#Similarly, one can also reinsert the conditions\n",
    "for galaxy_flow, galaxy in zip(flow_sample, Galaxies):\n",
    "    galaxy_flow[\"parameters\"] = galaxy[\"parameters\"]\n",
    "\n",
    "#Format in minutes and seconds\n",
    "print(f\"Time to sample: {int((time.perf_counter()-start)/60)} minutes and {int((time.perf_counter()-start)%60)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Get multiple galaxy plot\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m visual\u001b[39m.\u001b[39mplot_conditional_2(Data_sub_v, M_stars_sub_v, flow_sample, M_stars_sub_v, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mN\u001b[39m\u001b[39m\"\u001b[39m, label\u001b[39m=\u001b[39mfilename, N_unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmassperkpc\u001b[39m\u001b[39m\"\u001b[39m, color_pass\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m, global_grid\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visual' is not defined"
     ]
    }
   ],
   "source": [
    "#Get multiple galaxy plot\n",
    "visual.plot_conditional_2(Galaxies, flow_sample, type=\"N\", label=filename, N_unit=\"massperkpc\", color_pass=\"first\", global_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get comparison plot of single galaxy\n",
    "\n",
    "visual.get_result_plots(Galaxies[5], flow_sample[5], label=filename, format_=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.plot_conditional_histograms(flow_sample, label = filename, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.loss_plot(loss_results, tot_time=tot_time, savefig=filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
