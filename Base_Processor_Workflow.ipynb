{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Processor Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows what is necessary to use the flow with data and what the processor does hand how, to deal with this.\n",
    "\n",
    "It shows the low level base Workflow, that is also used by the API in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowcode\n",
    "import processing\n",
    "import res_flow_vis as visual\n",
    "import externalize as ext\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filename for a given run\n",
    "filename = \"leavout_MttZ_all_CL2_24_10_512_8_lo[66, 20, 88, 48, 5]\" #\"leavout_MttZ_MWs_CL2_24_10_512_8_lo5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate the processor\n",
    "mpc = processing.Processor_cond()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processor is an object that keeps track of the transformations applied to the data when normalizing for training, remembers the component names of the data before detaching to torch tensors and reverses all this when making inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load raw data, this loads the data from the files and processes it to the correct format\n",
    "Galaxies_raw = mpc.get_data(\"all_sims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stars': ['x', 'y', 'z', 'vx', 'vy', 'vz', 'Z', 'feh', 'ofe', 'mass', 'age']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note it also registers used quantitiy names\n",
    "mpc.component_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key \"stars\" contains a DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>Z</th>\n",
       "      <th>feh</th>\n",
       "      <th>ofe</th>\n",
       "      <th>mass</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.320762</td>\n",
       "      <td>13.947057</td>\n",
       "      <td>0.648117</td>\n",
       "      <td>-15.820096</td>\n",
       "      <td>15.730662</td>\n",
       "      <td>25.561372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.507547</td>\n",
       "      <td>0.466361</td>\n",
       "      <td>7830.175642</td>\n",
       "      <td>13.522674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.402683</td>\n",
       "      <td>-1.459748</td>\n",
       "      <td>1.174516</td>\n",
       "      <td>20.920114</td>\n",
       "      <td>-30.466823</td>\n",
       "      <td>-15.565336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.507547</td>\n",
       "      <td>0.466361</td>\n",
       "      <td>7830.176248</td>\n",
       "      <td>13.520988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.354377</td>\n",
       "      <td>4.079226</td>\n",
       "      <td>1.949618</td>\n",
       "      <td>1.926594</td>\n",
       "      <td>-109.700875</td>\n",
       "      <td>11.080549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.507547</td>\n",
       "      <td>0.466361</td>\n",
       "      <td>7830.176248</td>\n",
       "      <td>13.520145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.715224</td>\n",
       "      <td>-3.148012</td>\n",
       "      <td>-2.108494</td>\n",
       "      <td>35.815449</td>\n",
       "      <td>13.556570</td>\n",
       "      <td>-18.749363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.507547</td>\n",
       "      <td>0.466361</td>\n",
       "      <td>7830.176248</td>\n",
       "      <td>13.519302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.521244</td>\n",
       "      <td>7.460683</td>\n",
       "      <td>-2.849450</td>\n",
       "      <td>-12.839982</td>\n",
       "      <td>-9.406608</td>\n",
       "      <td>-12.336868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-41.507547</td>\n",
       "      <td>0.466361</td>\n",
       "      <td>7830.176248</td>\n",
       "      <td>13.519302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70473</th>\n",
       "      <td>4.176173</td>\n",
       "      <td>-7.198771</td>\n",
       "      <td>-1.684753</td>\n",
       "      <td>27.148138</td>\n",
       "      <td>46.779784</td>\n",
       "      <td>19.308997</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>-1.014137</td>\n",
       "      <td>0.063585</td>\n",
       "      <td>13192.044900</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70474</th>\n",
       "      <td>4.032141</td>\n",
       "      <td>-7.345427</td>\n",
       "      <td>-1.628008</td>\n",
       "      <td>11.584631</td>\n",
       "      <td>20.404142</td>\n",
       "      <td>14.985289</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-1.002988</td>\n",
       "      <td>0.064091</td>\n",
       "      <td>13193.044887</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70475</th>\n",
       "      <td>3.987357</td>\n",
       "      <td>-7.469818</td>\n",
       "      <td>-1.605336</td>\n",
       "      <td>10.797821</td>\n",
       "      <td>16.979302</td>\n",
       "      <td>12.951498</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>-1.010247</td>\n",
       "      <td>0.064449</td>\n",
       "      <td>13193.044887</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70476</th>\n",
       "      <td>4.009991</td>\n",
       "      <td>-7.326869</td>\n",
       "      <td>-1.702954</td>\n",
       "      <td>9.155321</td>\n",
       "      <td>25.086696</td>\n",
       "      <td>13.437631</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>-1.005108</td>\n",
       "      <td>0.060350</td>\n",
       "      <td>13193.044887</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70477</th>\n",
       "      <td>4.082187</td>\n",
       "      <td>-7.150516</td>\n",
       "      <td>-1.724685</td>\n",
       "      <td>18.229723</td>\n",
       "      <td>70.660979</td>\n",
       "      <td>27.988387</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>-1.015776</td>\n",
       "      <td>0.063545</td>\n",
       "      <td>13193.044887</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70478 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y         z         vx          vy         vz  \\\n",
       "0      8.320762  13.947057  0.648117 -15.820096   15.730662  25.561372   \n",
       "1      1.402683  -1.459748  1.174516  20.920114  -30.466823 -15.565336   \n",
       "2     -0.354377   4.079226  1.949618   1.926594 -109.700875  11.080549   \n",
       "3      0.715224  -3.148012 -2.108494  35.815449   13.556570 -18.749363   \n",
       "4     -5.521244   7.460683 -2.849450 -12.839982   -9.406608 -12.336868   \n",
       "...         ...        ...       ...        ...         ...        ...   \n",
       "70473  4.176173  -7.198771 -1.684753  27.148138   46.779784  19.308997   \n",
       "70474  4.032141  -7.345427 -1.628008  11.584631   20.404142  14.985289   \n",
       "70475  3.987357  -7.469818 -1.605336  10.797821   16.979302  12.951498   \n",
       "70476  4.009991  -7.326869 -1.702954   9.155321   25.086696  13.437631   \n",
       "70477  4.082187  -7.150516 -1.724685  18.229723   70.660979  27.988387   \n",
       "\n",
       "              Z        feh       ofe          mass        age  \n",
       "0      0.000000 -41.507547  0.466361   7830.175642  13.522674  \n",
       "1      0.000000 -41.507547  0.466361   7830.176248  13.520988  \n",
       "2      0.000000 -41.507547  0.466361   7830.176248  13.520145  \n",
       "3      0.000000 -41.507547  0.466361   7830.176248  13.519302  \n",
       "4      0.000000 -41.507547  0.466361   7830.176248  13.519302  \n",
       "...         ...        ...       ...           ...        ...  \n",
       "70473  0.002247  -1.014137  0.063585  13192.044900   0.000855  \n",
       "70474  0.002307  -1.002988  0.064091  13193.044887   0.000012  \n",
       "70475  0.002271  -1.010247  0.064449  13193.044887   0.000012  \n",
       "70476  0.002278  -1.005108  0.060350  13193.044887   0.000012  \n",
       "70477  0.002238  -1.015776  0.063545  13193.044887   0.000012  \n",
       "\n",
       "[70478 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key \"galaxy\" contains a dict:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'M_dm': 109636618947.82254,\n",
       " 'M_stars': 576316871.6737778,\n",
       " 'N_stars': 70478,\n",
       " 'id': 0,\n",
       " 'NIHAO_id': 'g1.05e11'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data format, see the documentation of Processor_cond for more details\n",
    "example_galaxy = Galaxies_raw[0]\n",
    "\n",
    "for key, value in example_galaxy.items():\n",
    "    print(f'key \"{key}\" contains a {type(value).__name__}:')\n",
    "    display(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.76316872e+08, 3.34649413e+06, 8.58793373e+08, 6.64246619e+06,\n",
       "       2.02812230e+09])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There is a nice function to get say the array of the stellar masses\n",
    "M_stars_raw = mpc.get_array(Galaxies_raw, \"galaxy\", \"M_stars\")\n",
    "print(len(M_stars_raw))\n",
    "M_stars_raw[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut out 5 of 95 galaxies, 2072015 of 34878379 stars (~6%).\n"
     ]
    }
   ],
   "source": [
    "#Clean data with specific algorithm\n",
    "#This algorithm will probably be needed to be changed for different datasets, see below\n",
    "Galaxies_cleaned = mpc.constraindata(Galaxies_raw, N_min=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M_dm': 109636618947.82254,\n",
       " 'M_stars': 547990391.3124597,\n",
       " 'N_stars': 66883,\n",
       " 'id': 0,\n",
       " 'NIHAO_id': 'g1.05e11'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will adjust e.g. total stellar mass\n",
    "id_0_galaxy = list(filter(lambda x: x[\"galaxy\"][\"id\"] == 0, Galaxies_cleaned))[0]\n",
    "\n",
    "id_0_galaxy[\"galaxy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Choose subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chose 90 of 90 galaxies.\n",
      "Chose 85 of 90 galaxies.\n"
     ]
    }
   ],
   "source": [
    "#Chose a subset of the data\n",
    "#1. Define conditions to be used\n",
    "#Done by supplying a function, that computes conditions from a galaxy (dict as above) and returns them with condition names (dict or DataFrame)\n",
    "cond_fn = ext.cond_M_stars_2age_avZ\n",
    "\n",
    "#2. Name the components to be used\n",
    "#Here ignore a stars mass as they are all equal due to simulation restrictions\n",
    "comp_use = [\"x\", \"y\", \"z\", \"vx\", \"vy\", \"vz\", \"Z\", \"feh\", \"ofe\", \"age\"]\n",
    "\n",
    "#3. Define the subset to be used (MWs, all, etc.)\n",
    "\n",
    "#Done by supplying a function that takes a galaxy and returns a boolean if it should be used\n",
    "#Subset to view for comaprison (e.g. all galaxies, no leavout i.e. contains validation set):\n",
    "#This function will leavout all galaxies that have galaxy[\"galaxy\"][\"id\"] in the supplied list\n",
    "use_fn_view = ext.construct_all_galaxies_leavout(\"id\", [])\n",
    "Galaxies = mpc.choose_subset(Galaxies_cleaned, use_fn = use_fn_view, cond_fn=cond_fn, comp_use=comp_use)\n",
    "\n",
    "#Subset to train on (e.g. all galaxies, leavout 5 as validation set):\n",
    "leavout_idices = [66, 20, 88, 48, 5]\n",
    "use_fn_train = ext.construct_all_galaxies_leavout(\"id\", leavout_idices)\n",
    "Galaxies_train = mpc.choose_subset(Galaxies_cleaned, use_fn = use_fn_train, cond_fn=cond_fn, comp_use=comp_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_stars</th>\n",
       "      <th>tau50</th>\n",
       "      <th>tau10</th>\n",
       "      <th>Z_av</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.479904e+08</td>\n",
       "      <td>4.942476</td>\n",
       "      <td>1.217085</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        M_stars     tau50     tau10      Z_av\n",
       "0  5.479904e+08  4.942476  1.217085  0.001316"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will add the conditions to the data under the key \"parameters\"\n",
    "id_0_galaxy = list(filter(lambda x: x[\"galaxy\"][\"id\"] == 0, Galaxies))[0]\n",
    "\n",
    "id_0_galaxy[\"parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stars': [], 'galaxy': ['M_stars', 'tau50', 'tau10', 'Z_av']}\n",
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#Note that the conditions are now also registered\n",
    "print(mpc.cond_names)\n",
    "\n",
    "#And that the galaxies with id in leavout_idices are not in the training data\n",
    "leavout_galaxies = filter(lambda x: x[\"galaxy\"][\"id\"] in leavout_idices, Galaxies_train)\n",
    "print(len(list(leavout_galaxies)))\n",
    "\n",
    "#But are in the view data\n",
    "leavout_galaxies = filter(lambda x: x[\"galaxy\"][\"id\"] in leavout_idices, Galaxies)\n",
    "print(len(list(leavout_galaxies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose device\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters of the flow\n",
    "LAYER_TYPE = flowcode.NSF_CL2\n",
    "N_LAYERS = 14\n",
    "COND_NAMES = mpc.cond_names[\"galaxy\"]\n",
    "DIM_COND = len(COND_NAMES)\n",
    "DIM_NOTCOND = len(Galaxies_train[0][\"stars\"]) - DIM_COND\n",
    "SPLIT = 0.5\n",
    "K = 10\n",
    "B = 3\n",
    "BASE_NETWORK = flowcode.MLP\n",
    "BASE_NETWORK_N_LAYERS = 4\n",
    "BASE_NETWORK_N_HIDDEN = 128\n",
    "BASE_NETWORK_LEAKY_RELU_SLOPE = 0.2\n",
    "\n",
    "SPLIT = {\"split\":SPLIT} if LAYER_TYPE == flowcode.NSF_CL else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "model = flowcode.NSFlow(N_LAYERS, DIM_NOTCOND, DIM_COND, LAYER_TYPE, **SPLIT, K=K, B=B, network=BASE_NETWORK, network_args=(BASE_NETWORK_N_HIDDEN,BASE_NETWORK_N_LAYERS,BASE_NETWORK_LEAKY_RELU_SLOPE))\n",
    "model = model.to(device)\n",
    "#Load pre-trained model\n",
    "#model.load_state_dict(torch.load(\"saves/leavout_M_star_MWs_CL2_24_10_512_8_lo1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "N_EPOCHS = 12\n",
    "INIT_LR = 0.00009\n",
    "GAMMA = 0.998\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The flow should be trained in normalized coordinates\n",
    "#Also we want e.g. total stellar mass to be learned in log\n",
    "\n",
    "#M_stars should be learned in log\n",
    "LOG_LEARN = [\"M_stars\"]\n",
    "\n",
    "#Define the transformations to be used\n",
    "transformations = (np.log10, )\n",
    "#Define the manes affected by the transformations (i.e. components of trf_names[i] are supplied to transformations[i])\n",
    "trf_names = (LOG_LEARN, )\n",
    "#Define the inverse transformations (these are applied to the model output)\n",
    "transformations_inv = (lambda x: 10**x, )\n",
    "#Define the logdets of the transformations needed if the pdf is to be computed\n",
    "logdets = (ext.logdet_log10,)\n",
    "\n",
    "#Now diststack will format the data to the correct format for the flow (one array of iid samples)\n",
    "#Essentially, it will stack all stars of all galaxies together and apend the conditions of the corresponding to each star\n",
    "#Data_to_flow will then normalize the data and apply the transformations\n",
    "#The returned data is to be used for training directly\n",
    "#IMPORTANT: Do not modify the returned data in any way:\n",
    "#The processor remembers e.g. the order of the components and will assume those when obtaining a sample from the flow and renaming them\n",
    "#Also remember e.g. (fÂ°g)^-1 = g^-1 Â° f^-1\n",
    "#so if you apply a transformation to the data, you would need to apply the inverse transformation to the flow output before the processor can use it\n",
    "#which is not possible as the processor directly applies the inverse transformation to the flow output\n",
    "Data_flow = mpc.Data_to_flow(mpc.diststack(Galaxies_train), transformations, trf_names, transformations_inv, transformation_logdets=logdets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that you can reproduce this exact normalization on other data by using mpc.reproduce_normalization\n",
    "#This can be used to transform some other data (e.g. your desired conditions when sampling from the flow) to normalized coordinates\n",
    "#the flow was trained on (I.e. it will not recalculate the normalization but use the one it was trained on)\n",
    "\n",
    "#The inverse is achieved with sample_to_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training takes long, so usually we do not want it in a notebook but in a nohup background process\n",
    "#E.g. it is possible to use the cond_trainer.py script to train the model\n",
    "#this will export the model and data accordingly to the cond_trainer folder\n",
    "torch.save(Data_flow, \"cond_trainer/data_cond_trainer.pth\")\n",
    "torch.save(model, \"cond_trainer/model_cond_trainer.pth\")\n",
    "np.save(\"cond_trainer/params_cond_trainer.npy\", np.append(COND_NAMES,np.array([N_EPOCHS,INIT_LR,BATCH_SIZE,GAMMA])))\n",
    "np.save(\"cond_trainer/filename_cond_trainer.npy\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start background training\n",
    "#nohup python cond_trainer.py <name_suffix> <optional:GPU id> &\n",
    "#Will save model in saves folder with loss history and train time (last entry in loss history)\n",
    "#Will flush training information to a textfile containing the name suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...OR train directly in notebook/current process\n",
    "import time\n",
    "train_loss_saver = []\n",
    "start = time.perf_counter()\n",
    "flowcode.train_flow(model, Data_flow, COND_NAMES, N_EPOCHS, lr=INIT_LR, batch_size=BATCH_SIZE, loss_saver=train_loss_saver, gamma=GAMMA)\n",
    "end = time.perf_counter()\n",
    "torch.save(model.state_dict(), f\"saves/{filename}.pth\")\n",
    "np.save(f\"saves/loss_{filename}.npy\",np.array(train_loss_saver+[end-start]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in training results:\n",
    "model.load_state_dict(torch.load(f\"saves/{filename}.pth\", map_location=device))\n",
    "loss_results = np.load(f\"saves/loss_{filename}.npy\")\n",
    "loss_results, tot_time = loss_results[:-1], loss_results[-1]/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to sample: 26 minutes and 41 seconds\n"
     ]
    }
   ],
   "source": [
    "#Get a sample from the flow\n",
    "use_GPUs = [9]\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "#Set a condition for the sample\n",
    "#Here, sample back all galaxies\n",
    "#I.e. Condition = all galaxy parameters as often as there are stars in the galaxy in a known order\n",
    "condition = mpc.diststack(Galaxies)[COND_NAMES]\n",
    "\n",
    "#Get sample with sample_Conditional\n",
    "#This will automatically:\n",
    "#1. Normalize the condition (using reproduce_normalization)\n",
    "#2. Sample from the flow\n",
    "\n",
    "#Denormalize the sample with sample_to_Data\n",
    "flow_sample = mpc.sample_to_Data(mpc.sample_Conditional(model, condition, split_size=int(6e5), GPUs=use_GPUs))\n",
    "\n",
    "#To revert to a galaxy interpretation we need to specify the number of stars belonging in each galaxy\n",
    "#Again, we use the same as in the data\n",
    "N_stars_galaxies = mpc.get_array(Galaxies, \"galaxy\" ,\"N_stars\")\n",
    "#or\n",
    "N_stars_galaxies = np.array([len(galaxy[\"stars\"]) for galaxy in Galaxies])\n",
    "\n",
    "#Convert sample to galaxy interpretation\n",
    "flow_sample = mpc.galaxysplit(flow_sample, N_stars_galaxies)\n",
    "\n",
    "#However this is now list of pandas dataframes, not a list of dictionaries as the original data\n",
    "#we can convert it back to a list of dictionaries\n",
    "flow_sample = [{\"stars\":galaxy_stars} for galaxy_stars in flow_sample]\n",
    "#In our special case, we can also reinsert the galaxy information that we know from the original data\n",
    "#This is of course not possible in general\n",
    "for galaxy_flow, galaxy in zip(flow_sample, Galaxies):\n",
    "    galaxy_flow[\"galaxy\"] = galaxy[\"galaxy\"]\n",
    "\n",
    "#Similarly, one can also reinsert the conditions\n",
    "for galaxy_flow, galaxy in zip(flow_sample, Galaxies):\n",
    "    galaxy_flow[\"parameters\"] = galaxy[\"parameters\"]\n",
    "\n",
    "#Format in minutes and seconds\n",
    "print(f\"Time to sample: {int((time.perf_counter()-start)/60)} minutes and {int((time.perf_counter()-start)%60)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Get multiple galaxy plot\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m visual\u001b[39m.\u001b[39mplot_conditional_2(Data_sub_v, M_stars_sub_v, flow_sample, M_stars_sub_v, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mN\u001b[39m\u001b[39m\"\u001b[39m, label\u001b[39m=\u001b[39mfilename, N_unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmassperkpc\u001b[39m\u001b[39m\"\u001b[39m, color_pass\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m, global_grid\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visual' is not defined"
     ]
    }
   ],
   "source": [
    "#Get multiple galaxy plot\n",
    "visual.plot_conditional_2(Galaxies, flow_sample, type=\"N\", label=filename, N_unit=\"massperkpc\", color_pass=\"first\", global_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get comparison plot of single galaxy\n",
    "\n",
    "visual.get_result_plots(Galaxies[5], flow_sample[5], label=filename, format_=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.plot_conditional_histograms(flow_sample, label = filename, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.loss_plot(loss_results, tot_time=tot_time, savefig=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also the pdf can be computed\n",
    "#This automatically:\n",
    "#1. Normalizes the points\n",
    "#2. Computes the pdf\n",
    "#3. Denormalizes the pdf i.e. respects the transformation_logdets\n",
    "Points = mpc.diststack(Galaxies)\n",
    "log_prob = mpc.log_prob(model, Points, GPUs=use_GPUs, split_size=int(6e5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
