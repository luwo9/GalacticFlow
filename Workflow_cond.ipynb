{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowcode\n",
    "import processing\n",
    "import res_flow_vis as visual\n",
    "import device_use\n",
    "import externalize as ext\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filename associated with this specific run\n",
    "filename = \"leavout_MttZ_MWs_CL2_24_10_512_8_lo15\" #\"leavout_MttZ_MWs_CL2_24_10_512_8_lo5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate a processor to handle data\n",
    "mpc = processing.Processor_cond(N_min=500, percentile2=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load raw data\n",
    "Data, N_stars, M_stars, M_dm = mpc.get_data(\"all_sims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data\n",
    "Data_const, N_stars_const, M_stars_const, M_dm_const = mpc.constraindata(Data, M_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chose a subset of the data\n",
    "#Subset to view for comaprison\n",
    "Data_sub_v, N_stars_sub_v, M_stars_sub_v, M_dm_sub_v = mpc.choose_subset(Data_const, N_stars_const, M_stars_const, M_dm_const, use_fn = ext.MW_like_galaxy, cond_fn=ext.cond_M_stars_2age_avZ)\n",
    "\n",
    "#Subset to train on (e.g. leave one out):\n",
    "leavout_idices = 15\n",
    "leavout_fn = ext.construct_MW_like_galaxy_leavout(M_dm_sub_v[leavout_idices])\n",
    "Data_sub, N_stars_sub, M_stars_sub, M_dm_sub = mpc.choose_subset(Data_const, N_stars_const, M_stars_const, M_dm_const, use_fn = leavout_fn, cond_fn=ext.cond_M_stars_2age_avZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose device\n",
    "device = \"cpu\" #device_use.device_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters of the flow\n",
    "LAYER_TYPE = flowcode.NSF_CL2\n",
    "N_LAYERS = 24\n",
    "COND_INDS = np.array([10,11,12,13])\n",
    "DIM_COND = COND_INDS.shape[0]\n",
    "DIM_NOTCOND = Data_sub[0].shape[1] - DIM_COND\n",
    "SPLIT = 0.5\n",
    "K = 10\n",
    "B = 3\n",
    "BASE_NETWORK = flowcode.MLP\n",
    "BASE_NETWORK_N_LAYERS = 8\n",
    "BASE_NETWORK_N_HIDDEN = 512\n",
    "BASE_NETWORK_LEAKY_RELU_SLOPE = 0.2\n",
    "\n",
    "SPLIT = {\"split\":SPLIT} if LAYER_TYPE == flowcode.NSF_CL else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model\n",
    "model = flowcode.NSFlow(N_LAYERS, DIM_NOTCOND, DIM_COND, LAYER_TYPE, **SPLIT, K=K, B=B, network=BASE_NETWORK, network_args=(BASE_NETWORK_N_HIDDEN,BASE_NETWORK_N_LAYERS,BASE_NETWORK_LEAKY_RELU_SLOPE))\n",
    "model = model.to(device)\n",
    "#Load pre-trained model\n",
    "#model.load_state_dict(torch.load(\"saves/leavout_M_star_MWs_CL2_24_10_512_8_lo1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "N_EPOCHS = 12\n",
    "INIT_LR = 0.00009\n",
    "GAMMA = 0.998\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "#Define indices for preprocessing\n",
    "LOG_LEARN = np.array([10])\n",
    "SMOOTHEN_MAX = np.array([7,8,9])\n",
    "SMOOTHEN_MIN = np.array([6,9])\n",
    "\n",
    "#Define functions for preprocessing\n",
    "max_s = ext.tanh_smooth(\"max\")\n",
    "min_s = ext.tanh_smooth(\"min\")\n",
    "\n",
    "#Define collections\n",
    "transformations = (np.log10, )#max_s.smooth, min_s.smooth)\n",
    "trf_indices = (LOG_LEARN, )#SMOOTHEN_MAX, SMOOTHEN_MIN)\n",
    "transformations_inv = (lambda x: 10**x, )#max_s.smooth_inv, min_s.smooth_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for flow\n",
    "Data_flow = mpc.Data_to_flow(mpc.diststack(Data_sub), transformations, trf_indices, transformations_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save relevant data to the drive for external python file (device needs to be GPU) to do the training in background...\n",
    "torch.save(Data_flow, \"cond_trainer/data_cond_trainer.pth\")\n",
    "torch.save(model, \"cond_trainer/model_cond_trainer.pth\")\n",
    "np.save(\"cond_trainer/params_cond_trainer.npy\", np.append(COND_INDS,np.array([N_EPOCHS,INIT_LR,BATCH_SIZE,GAMMA])))\n",
    "np.save(\"cond_trainer/filename_cond_trainer.npy\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start background training\n",
    "import subprocess\n",
    "subprocess.Popen(\"nohup python3 cond_trainer.py &\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...OR train here\n",
    "import time\n",
    "train_loss_saver = []\n",
    "start = time.perf_counter()\n",
    "flowcode.train_flow(model, Data_flow, COND_INDS, N_EPOCHS, lr=INIT_LR, batch_size=BATCH_SIZE, loss_saver=train_loss_saver, gamma=GAMMA)\n",
    "end = time.perf_counter()\n",
    "torch.save(model.state_dict(), f\"saves/{filename}.pth\")\n",
    "np.save(f\"saves/loss_{filename}.npy\",np.array(train_loss_saver+[end-start]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in training results:\n",
    "model.load_state_dict(torch.load(f\"saves/{filename}.pth\", map_location=device))\n",
    "loss_results = np.load(f\"saves/loss_{filename}.npy\")\n",
    "loss_results, tot_time = loss_results[:-1], loss_results[-1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a sample from the flow\n",
    "use_GPUs = [1,2,3,4,6,7,8]\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "#Set a condition for the sample\n",
    "condition = mpc.diststack(Data_sub_v)[:,COND_INDS]\n",
    "\n",
    "#Get sample\n",
    "flow_sample = mpc.galaxysplit(mpc.sample_to_Data(mpc.sample_Conditional(model, COND_INDS, condition, split_size=int(6e5), GPUs=use_GPUs)), N_stars_sub_v)\n",
    "#Format in minutes and seconds\n",
    "print(f\"Time to sample: {int((time.perf_counter()-start)/60)} minutes and {int((time.perf_counter()-start)%60)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get multiple galaxy plot\n",
    "visual.plot_conditional_2(Data_sub_v, M_stars_sub_v, flow_sample, M_stars_sub_v, type=\"N\", label=filename, N_unit=\"massperkpc\", color_pass=\"first\", global_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get comparison plot of single galaxy\n",
    "\n",
    "visual.get_result_plots(Data_sub_v[15], flow_sample[15], label=filename, format_=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.plot_conditional_histograms(flow_sample, M_stars_sub, label = filename, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.loss_plot(loss_results, tot_time=tot_time, savefig=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(visual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
